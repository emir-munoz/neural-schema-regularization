Using Theano backend.
INFO:root:Acquiring data/wn18/wordnet-mlj12-train.txt ..
INFO:root:Acquiring data/wn18/wordnet-mlj12-valid.txt ..
INFO:root:Acquiring data/wn18/wordnet-mlj12-test.txt ..
INFO:root:Samples: 141442, no. batches: 10 -> batch size: 14145
INFO:root:Epoch no. 1 of 500 (samples: 141442)
INFO:root:Loss: 3.1707 +/- 0.1463
INFO:root:Epoch no. 2 of 500 (samples: 141442)
INFO:root:Loss: 2.4154 +/- 0.0816
INFO:root:Epoch no. 3 of 500 (samples: 141442)
INFO:root:Loss: 1.8647 +/- 0.0465
INFO:root:Epoch no. 4 of 500 (samples: 141442)
INFO:root:Loss: 1.4691 +/- 0.0267
INFO:root:Epoch no. 5 of 500 (samples: 141442)
INFO:root:Loss: 1.1886 +/- 0.0141
INFO:root:Epoch no. 6 of 500 (samples: 141442)
INFO:root:Loss: 0.9549 +/- 0.0147
INFO:root:Epoch no. 7 of 500 (samples: 141442)
INFO:root:Loss: 0.7721 +/- 0.0147
INFO:root:Epoch no. 8 of 500 (samples: 141442)
INFO:root:Loss: 0.6299 +/- 0.0092
INFO:root:Epoch no. 9 of 500 (samples: 141442)
INFO:root:Loss: 0.5115 +/- 0.0078
INFO:root:Epoch no. 10 of 500 (samples: 141442)
INFO:root:Loss: 0.4287 +/- 0.0083
INFO:root:Epoch no. 11 of 500 (samples: 141442)
INFO:root:Loss: 0.3641 +/- 0.0074
INFO:root:Epoch no. 12 of 500 (samples: 141442)
INFO:root:Loss: 0.3195 +/- 0.0062
INFO:root:Epoch no. 13 of 500 (samples: 141442)
INFO:root:Loss: 0.2806 +/- 0.0046
INFO:root:Epoch no. 14 of 500 (samples: 141442)
INFO:root:Loss: 0.2499 +/- 0.0082
INFO:root:Epoch no. 15 of 500 (samples: 141442)
INFO:root:Loss: 0.2262 +/- 0.0066
INFO:root:Epoch no. 16 of 500 (samples: 141442)
INFO:root:Loss: 0.2066 +/- 0.0071
INFO:root:Epoch no. 17 of 500 (samples: 141442)
INFO:root:Loss: 0.1901 +/- 0.0071
INFO:root:Epoch no. 18 of 500 (samples: 141442)
INFO:root:Loss: 0.1769 +/- 0.0041
INFO:root:Epoch no. 19 of 500 (samples: 141442)
INFO:root:Loss: 0.1655 +/- 0.0039
INFO:root:Epoch no. 20 of 500 (samples: 141442)
INFO:root:Loss: 0.1582 +/- 0.004
INFO:root:Epoch no. 21 of 500 (samples: 141442)
INFO:root:Loss: 0.1471 +/- 0.0032
INFO:root:Epoch no. 22 of 500 (samples: 141442)
INFO:root:Loss: 0.14 +/- 0.0034
INFO:root:Epoch no. 23 of 500 (samples: 141442)
INFO:root:Loss: 0.133 +/- 0.0043
INFO:root:Epoch no. 24 of 500 (samples: 141442)
INFO:root:Loss: 0.1282 +/- 0.003
INFO:root:Epoch no. 25 of 500 (samples: 141442)
INFO:root:Loss: 0.1222 +/- 0.0029
INFO:root:Epoch no. 26 of 500 (samples: 141442)
INFO:root:Loss: 0.1167 +/- 0.0049
INFO:root:Epoch no. 27 of 500 (samples: 141442)
INFO:root:Loss: 0.1125 +/- 0.0038
INFO:root:Epoch no. 28 of 500 (samples: 141442)
INFO:root:Loss: 0.1084 +/- 0.0042
INFO:root:Epoch no. 29 of 500 (samples: 141442)
INFO:root:Loss: 0.1055 +/- 0.0019
INFO:root:Epoch no. 30 of 500 (samples: 141442)
Traceback (most recent call last):
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/hyper-cli.py", line 324, in <module>
    main(sys.argv[1:])
  File "./bin/hyper-cli.py", line 293, in main
    visualize=is_visualize)
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/learning/core.py", line 185, in pairwise_training
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/models.py", line 409, in fit
    sample_weight=sample_weight)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/training.py", line 1052, in fit
    callback_metrics=callback_metrics)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/training.py", line 790, in _fit_loop
    outs = f(ins_batch)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/backend/theano_backend.py", line 518, in __call__
    return self.function(*inputs)
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/usr/local/lib/python3.4/dist-packages/theano/gof/link.py", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/usr/local/lib/python3.4/dist-packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
MemoryError: 
Apply node that caused the error: Elemwise{mul}(Reshape{3}.0, InplaceDimShuffle{0,x,x}.0, InplaceDimShuffle{0,x,1}.0)
Toposort index: 91
Inputs types: [TensorType(float32, (False, False, True)), TensorType(float32, (False, True, True)), TensorType(float32, (False, True, False))]
Inputs shapes: [(42435, 50, 1), (42435, 1, 1), (42435, 1, 50)]
Inputs strides: [(400, 4, 4), (4, 4, 4), (400, 200, 4)]
Inputs values: ['not shown', 'not shown', 'not shown']
Outputs clients: [[Reshape{2}(Elemwise{mul}.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
