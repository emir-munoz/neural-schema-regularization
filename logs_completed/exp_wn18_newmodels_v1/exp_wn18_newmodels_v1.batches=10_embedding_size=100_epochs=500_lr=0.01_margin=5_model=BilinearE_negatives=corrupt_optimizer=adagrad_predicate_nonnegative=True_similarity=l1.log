Using Theano backend.
INFO:root:Acquiring data/wn18/wordnet-mlj12-train.txt ..
INFO:root:Acquiring data/wn18/wordnet-mlj12-valid.txt ..
INFO:root:Acquiring data/wn18/wordnet-mlj12-test.txt ..
INFO:root:Samples: 141442, no. batches: 10 -> batch size: 14145
INFO:root:Epoch no. 1 of 500 (samples: 141442)
INFO:root:Loss: 3.2882 +/- 0.0993
INFO:root:Epoch no. 2 of 500 (samples: 141442)
INFO:root:Loss: 3.1436 +/- 0.0099
INFO:root:Epoch no. 3 of 500 (samples: 141442)
INFO:root:Loss: 3.0395 +/- 0.0079
INFO:root:Epoch no. 4 of 500 (samples: 141442)
INFO:root:Loss: 2.9286 +/- 0.0131
INFO:root:Epoch no. 5 of 500 (samples: 141442)
INFO:root:Loss: 2.7983 +/- 0.0179
INFO:root:Epoch no. 6 of 500 (samples: 141442)
INFO:root:Loss: 2.66 +/- 0.0179
INFO:root:Epoch no. 7 of 500 (samples: 141442)
INFO:root:Loss: 2.526 +/- 0.0105
INFO:root:Epoch no. 8 of 500 (samples: 141442)
INFO:root:Loss: 2.4109 +/- 0.0078
INFO:root:Epoch no. 9 of 500 (samples: 141442)
INFO:root:Loss: 2.3106 +/- 0.0092
INFO:root:Epoch no. 10 of 500 (samples: 141442)
INFO:root:Loss: 2.2262 +/- 0.0073
INFO:root:Epoch no. 11 of 500 (samples: 141442)
INFO:root:Loss: 2.1523 +/- 0.0094
INFO:root:Epoch no. 12 of 500 (samples: 141442)
INFO:root:Loss: 2.0895 +/- 0.009
INFO:root:Epoch no. 13 of 500 (samples: 141442)
INFO:root:Loss: 2.0348 +/- 0.0114
INFO:root:Epoch no. 14 of 500 (samples: 141442)
INFO:root:Loss: 1.9899 +/- 0.0076
INFO:root:Epoch no. 15 of 500 (samples: 141442)
INFO:root:Loss: 1.9449 +/- 0.0083
INFO:root:Epoch no. 16 of 500 (samples: 141442)
INFO:root:Loss: 1.9051 +/- 0.0145
INFO:root:Epoch no. 17 of 500 (samples: 141442)
INFO:root:Loss: 1.8689 +/- 0.0127
INFO:root:Epoch no. 18 of 500 (samples: 141442)
INFO:root:Loss: 1.835 +/- 0.013
INFO:root:Epoch no. 19 of 500 (samples: 141442)
INFO:root:Loss: 1.8079 +/- 0.0119
INFO:root:Epoch no. 20 of 500 (samples: 141442)
INFO:root:Loss: 1.7776 +/- 0.011
INFO:root:Epoch no. 21 of 500 (samples: 141442)
INFO:root:Loss: 1.7517 +/- 0.011
INFO:root:Epoch no. 22 of 500 (samples: 141442)
INFO:root:Loss: 1.7241 +/- 0.0154
INFO:root:Epoch no. 23 of 500 (samples: 141442)
INFO:root:Loss: 1.7016 +/- 0.0098
INFO:root:Epoch no. 24 of 500 (samples: 141442)
INFO:root:Loss: 1.6769 +/- 0.0125
INFO:root:Epoch no. 25 of 500 (samples: 141442)
INFO:root:Loss: 1.6577 +/- 0.0096
INFO:root:Epoch no. 26 of 500 (samples: 141442)
INFO:root:Loss: 1.636 +/- 0.0113
INFO:root:Epoch no. 27 of 500 (samples: 141442)
INFO:root:Loss: 1.6171 +/- 0.0063
INFO:root:Epoch no. 28 of 500 (samples: 141442)
INFO:root:Loss: 1.5993 +/- 0.0131
INFO:root:Epoch no. 29 of 500 (samples: 141442)
INFO:root:Loss: 1.5786 +/- 0.0135
INFO:root:Epoch no. 30 of 500 (samples: 141442)
INFO:root:Loss: 1.5602 +/- 0.012
INFO:root:Epoch no. 31 of 500 (samples: 141442)
INFO:root:Loss: 1.5424 +/- 0.0086
INFO:root:Epoch no. 32 of 500 (samples: 141442)
INFO:root:Loss: 1.5246 +/- 0.0104
INFO:root:Epoch no. 33 of 500 (samples: 141442)
INFO:root:Loss: 1.5054 +/- 0.0156
INFO:root:Epoch no. 34 of 500 (samples: 141442)
INFO:root:Loss: 1.4925 +/- 0.0093
INFO:root:Epoch no. 35 of 500 (samples: 141442)
INFO:root:Loss: 1.4749 +/- 0.0096
INFO:root:Epoch no. 36 of 500 (samples: 141442)
INFO:root:Loss: 1.4586 +/- 0.0113
INFO:root:Epoch no. 37 of 500 (samples: 141442)
INFO:root:Loss: 1.4436 +/- 0.0104
INFO:root:Epoch no. 38 of 500 (samples: 141442)
INFO:root:Loss: 1.4306 +/- 0.0075
INFO:root:Epoch no. 39 of 500 (samples: 141442)
INFO:root:Loss: 1.4144 +/- 0.0092
INFO:root:Epoch no. 40 of 500 (samples: 141442)
INFO:root:Loss: 1.3982 +/- 0.0071
INFO:root:Epoch no. 41 of 500 (samples: 141442)
INFO:root:Loss: 1.3862 +/- 0.012
INFO:root:Epoch no. 42 of 500 (samples: 141442)
INFO:root:Loss: 1.3713 +/- 0.0101
INFO:root:Epoch no. 43 of 500 (samples: 141442)
INFO:root:Loss: 1.361 +/- 0.0099
INFO:root:Epoch no. 44 of 500 (samples: 141442)
INFO:root:Loss: 1.3471 +/- 0.0082
INFO:root:Epoch no. 45 of 500 (samples: 141442)
INFO:root:Loss: 1.3318 +/- 0.0088
INFO:root:Epoch no. 46 of 500 (samples: 141442)
INFO:root:Loss: 1.321 +/- 0.0075
INFO:root:Epoch no. 47 of 500 (samples: 141442)
INFO:root:Loss: 1.308 +/- 0.0112
INFO:root:Epoch no. 48 of 500 (samples: 141442)
INFO:root:Loss: 1.2948 +/- 0.0106
INFO:root:Epoch no. 49 of 500 (samples: 141442)
INFO:root:Loss: 1.2784 +/- 0.0056
INFO:root:Epoch no. 50 of 500 (samples: 141442)
INFO:root:Loss: 1.2733 +/- 0.0089
INFO:root:Epoch no. 51 of 500 (samples: 141442)
INFO:root:Loss: 1.2608 +/- 0.008
INFO:root:Epoch no. 52 of 500 (samples: 141442)
INFO:root:Loss: 1.2482 +/- 0.0091
INFO:root:Epoch no. 53 of 500 (samples: 141442)
INFO:root:Loss: 1.2404 +/- 0.011
INFO:root:Epoch no. 54 of 500 (samples: 141442)
INFO:root:Loss: 1.2284 +/- 0.0073
INFO:root:Epoch no. 55 of 500 (samples: 141442)
INFO:root:Loss: 1.2186 +/- 0.009
INFO:root:Epoch no. 56 of 500 (samples: 141442)
INFO:root:Loss: 1.2062 +/- 0.0076
INFO:root:Epoch no. 57 of 500 (samples: 141442)
INFO:root:Loss: 1.1975 +/- 0.0083
INFO:root:Epoch no. 58 of 500 (samples: 141442)
INFO:root:Loss: 1.1893 +/- 0.0088
INFO:root:Epoch no. 59 of 500 (samples: 141442)
INFO:root:Loss: 1.1802 +/- 0.0062
INFO:root:Epoch no. 60 of 500 (samples: 141442)
INFO:root:Loss: 1.1708 +/- 0.0082
INFO:root:Epoch no. 61 of 500 (samples: 141442)
INFO:root:Loss: 1.1598 +/- 0.0073
INFO:root:Epoch no. 62 of 500 (samples: 141442)
INFO:root:Loss: 1.1522 +/- 0.0089
INFO:root:Epoch no. 63 of 500 (samples: 141442)
INFO:root:Loss: 1.1442 +/- 0.0078
INFO:root:Epoch no. 64 of 500 (samples: 141442)
INFO:root:Loss: 1.1339 +/- 0.0065
INFO:root:Epoch no. 65 of 500 (samples: 141442)
INFO:root:Loss: 1.1274 +/- 0.0065
INFO:root:Epoch no. 66 of 500 (samples: 141442)
INFO:root:Loss: 1.1156 +/- 0.0095
INFO:root:Epoch no. 67 of 500 (samples: 141442)
INFO:root:Loss: 1.1076 +/- 0.0034
INFO:root:Epoch no. 68 of 500 (samples: 141442)
INFO:root:Loss: 1.1 +/- 0.0083
INFO:root:Epoch no. 69 of 500 (samples: 141442)
INFO:root:Loss: 1.0941 +/- 0.0053
INFO:root:Epoch no. 70 of 500 (samples: 141442)
INFO:root:Loss: 1.082 +/- 0.0055
INFO:root:Epoch no. 71 of 500 (samples: 141442)
INFO:root:Loss: 1.0813 +/- 0.009
INFO:root:Epoch no. 72 of 500 (samples: 141442)
INFO:root:Loss: 1.0727 +/- 0.0065
INFO:root:Epoch no. 73 of 500 (samples: 141442)
INFO:root:Loss: 1.0659 +/- 0.0078
INFO:root:Epoch no. 74 of 500 (samples: 141442)
INFO:root:Loss: 1.0559 +/- 0.0074
INFO:root:Epoch no. 75 of 500 (samples: 141442)
INFO:root:Loss: 1.0466 +/- 0.0062
INFO:root:Epoch no. 76 of 500 (samples: 141442)
INFO:root:Loss: 1.0438 +/- 0.0097
INFO:root:Epoch no. 77 of 500 (samples: 141442)
INFO:root:Loss: 1.0358 +/- 0.0066
INFO:root:Epoch no. 78 of 500 (samples: 141442)
INFO:root:Loss: 1.0275 +/- 0.0076
INFO:root:Epoch no. 79 of 500 (samples: 141442)
INFO:root:Loss: 1.0208 +/- 0.0073
INFO:root:Epoch no. 80 of 500 (samples: 141442)
INFO:root:Loss: 1.0139 +/- 0.0067
INFO:root:Epoch no. 81 of 500 (samples: 141442)
INFO:root:Loss: 1.0122 +/- 0.0048
INFO:root:Epoch no. 82 of 500 (samples: 141442)
INFO:root:Loss: 1.0044 +/- 0.0112
INFO:root:Epoch no. 83 of 500 (samples: 141442)
INFO:root:Loss: 0.9977 +/- 0.0069
INFO:root:Epoch no. 84 of 500 (samples: 141442)
INFO:root:Loss: 0.9896 +/- 0.0061
INFO:root:Epoch no. 85 of 500 (samples: 141442)
INFO:root:Loss: 0.987 +/- 0.0077
INFO:root:Epoch no. 86 of 500 (samples: 141442)
INFO:root:Loss: 0.9786 +/- 0.008
INFO:root:Epoch no. 87 of 500 (samples: 141442)
INFO:root:Loss: 0.9727 +/- 0.0077
INFO:root:Epoch no. 88 of 500 (samples: 141442)
INFO:root:Loss: 0.9695 +/- 0.0087
INFO:root:Epoch no. 89 of 500 (samples: 141442)
INFO:root:Loss: 0.9653 +/- 0.0063
INFO:root:Epoch no. 90 of 500 (samples: 141442)
INFO:root:Loss: 0.9554 +/- 0.004
INFO:root:Epoch no. 91 of 500 (samples: 141442)
INFO:root:Loss: 0.9534 +/- 0.0043
INFO:root:Epoch no. 92 of 500 (samples: 141442)
INFO:root:Loss: 0.9423 +/- 0.0073
INFO:root:Epoch no. 93 of 500 (samples: 141442)
INFO:root:Loss: 0.9423 +/- 0.0054
INFO:root:Epoch no. 94 of 500 (samples: 141442)
INFO:root:Loss: 0.9378 +/- 0.012
INFO:root:Epoch no. 95 of 500 (samples: 141442)
INFO:root:Loss: 0.9329 +/- 0.0113
INFO:root:Epoch no. 96 of 500 (samples: 141442)
INFO:root:Loss: 0.9268 +/- 0.007
INFO:root:Epoch no. 97 of 500 (samples: 141442)
INFO:root:Loss: 0.9203 +/- 0.0069
INFO:root:Epoch no. 98 of 500 (samples: 141442)
INFO:root:Loss: 0.9179 +/- 0.0058
INFO:root:Epoch no. 99 of 500 (samples: 141442)
INFO:root:Loss: 0.9135 +/- 0.007
INFO:root:Epoch no. 100 of 500 (samples: 141442)
INFO:root:Loss: 0.9059 +/- 0.0062
INFO:root:Epoch no. 101 of 500 (samples: 141442)
INFO:root:Loss: 0.8986 +/- 0.01
INFO:root:Epoch no. 102 of 500 (samples: 141442)
INFO:root:Loss: 0.9004 +/- 0.0046
INFO:root:Epoch no. 103 of 500 (samples: 141442)
INFO:root:Loss: 0.8963 +/- 0.0057
INFO:root:Epoch no. 104 of 500 (samples: 141442)
INFO:root:Loss: 0.8882 +/- 0.0066
INFO:root:Epoch no. 105 of 500 (samples: 141442)
INFO:root:Loss: 0.8824 +/- 0.0073
INFO:root:Epoch no. 106 of 500 (samples: 141442)
INFO:root:Loss: 0.8806 +/- 0.0072
INFO:root:Epoch no. 107 of 500 (samples: 141442)
INFO:root:Loss: 0.8747 +/- 0.0046
INFO:root:Epoch no. 108 of 500 (samples: 141442)
INFO:root:Loss: 0.8745 +/- 0.0042
INFO:root:Epoch no. 109 of 500 (samples: 141442)
Traceback (most recent call last):
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/hyper-cli.py", line 324, in <module>
    main(sys.argv[1:])
  File "./bin/hyper-cli.py", line 293, in main
    visualize=is_visualize)
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/learning/core.py", line 185, in pairwise_training
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/models.py", line 409, in fit
    sample_weight=sample_weight)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/training.py", line 1052, in fit
    callback_metrics=callback_metrics)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/training.py", line 790, in _fit_loop
    outs = f(ins_batch)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/backend/theano_backend.py", line 518, in __call__
    return self.function(*inputs)
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/usr/local/lib/python3.4/dist-packages/theano/gof/link.py", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/usr/local/lib/python3.4/dist-packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
MemoryError: 
Apply node that caused the error: Elemwise{mul,no_inplace}(Reshape{3}.0, Reshape{3}.0)
Toposort index: 54
Inputs types: [TensorType(float32, (False, False, True)), TensorType(float32, 3D)]
Inputs shapes: [(42435, 100, 1), (42435, 100, 100)]
Inputs strides: [(800, 4, 4), (40000, 400, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Sum{axis=[1], acc_dtype=float64}(Elemwise{mul,no_inplace}.0)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File "./bin/hyper-cli.py", line 293, in main
    visualize=is_visualize)
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/learning/core.py", line 78, in pairwise_training
    merge_layer = Merge([predicate_encoder, entity_encoder], mode=merge_function, output_shape=lambda _: (None, 1))
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 1116, in __init__
    self.add_inbound_node(layers, node_indices, tensor_indices)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 543, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 153, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors, mask=input_masks))
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 1193, in call
    return self.mode(inputs, **arguments)
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/layers/core.py", line 28, in latent_distance_binary_merge_function
    return merge_function(args, similarity=similarity_function)
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/layers/binary/merge_functions.py", line 186, in bilinear_merge_function
    bilinear_transformation = (rx * rW).sum(1)

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
