Using Theano backend.
INFO:root:Acquiring data/wn18/wordnet-mlj12-train.txt ..
INFO:root:Acquiring data/wn18/wordnet-mlj12-valid.txt ..
INFO:root:Acquiring data/wn18/wordnet-mlj12-test.txt ..
INFO:root:Samples: 141442, no. batches: 10 -> batch size: 14145
INFO:root:Epoch no. 1 of 500 (samples: 141442)
INFO:root:Loss: 1.3322 +/- 0.0011
INFO:root:Epoch no. 2 of 500 (samples: 141442)
INFO:root:Loss: 1.3156 +/- 0.0042
INFO:root:Epoch no. 3 of 500 (samples: 141442)
INFO:root:Loss: 1.2788 +/- 0.0116
INFO:root:Epoch no. 4 of 500 (samples: 141442)
INFO:root:Loss: 1.2106 +/- 0.0156
INFO:root:Epoch no. 5 of 500 (samples: 141442)
INFO:root:Loss: 1.1416 +/- 0.0122
INFO:root:Epoch no. 6 of 500 (samples: 141442)
INFO:root:Loss: 1.0929 +/- 0.0068
INFO:root:Epoch no. 7 of 500 (samples: 141442)
INFO:root:Loss: 1.0609 +/- 0.0062
INFO:root:Epoch no. 8 of 500 (samples: 141442)
INFO:root:Loss: 1.039 +/- 0.0051
INFO:root:Epoch no. 9 of 500 (samples: 141442)
INFO:root:Loss: 1.0233 +/- 0.0039
INFO:root:Epoch no. 10 of 500 (samples: 141442)
INFO:root:Loss: 1.0099 +/- 0.0037
INFO:root:Epoch no. 11 of 500 (samples: 141442)
INFO:root:Loss: 1.0001 +/- 0.0033
INFO:root:Epoch no. 12 of 500 (samples: 141442)
INFO:root:Loss: 0.9897 +/- 0.0058
INFO:root:Epoch no. 13 of 500 (samples: 141442)
INFO:root:Loss: 0.9816 +/- 0.0038
INFO:root:Epoch no. 14 of 500 (samples: 141442)
INFO:root:Loss: 0.9737 +/- 0.0029
INFO:root:Epoch no. 15 of 500 (samples: 141442)
INFO:root:Loss: 0.9659 +/- 0.0037
INFO:root:Epoch no. 16 of 500 (samples: 141442)
INFO:root:Loss: 0.9589 +/- 0.0049
INFO:root:Epoch no. 17 of 500 (samples: 141442)
INFO:root:Loss: 0.9508 +/- 0.0051
INFO:root:Epoch no. 18 of 500 (samples: 141442)
INFO:root:Loss: 0.945 +/- 0.0029
INFO:root:Epoch no. 19 of 500 (samples: 141442)
INFO:root:Loss: 0.9382 +/- 0.0031
INFO:root:Epoch no. 20 of 500 (samples: 141442)
INFO:root:Loss: 0.9307 +/- 0.0029
INFO:root:Epoch no. 21 of 500 (samples: 141442)
INFO:root:Loss: 0.924 +/- 0.0042
INFO:root:Epoch no. 22 of 500 (samples: 141442)
INFO:root:Loss: 0.9168 +/- 0.0032
INFO:root:Epoch no. 23 of 500 (samples: 141442)
INFO:root:Loss: 0.9103 +/- 0.0034
INFO:root:Epoch no. 24 of 500 (samples: 141442)
INFO:root:Loss: 0.9032 +/- 0.0024
INFO:root:Epoch no. 25 of 500 (samples: 141442)
INFO:root:Loss: 0.8965 +/- 0.0038
INFO:root:Epoch no. 26 of 500 (samples: 141442)
INFO:root:Loss: 0.8893 +/- 0.0044
INFO:root:Epoch no. 27 of 500 (samples: 141442)
INFO:root:Loss: 0.8841 +/- 0.0031
INFO:root:Epoch no. 28 of 500 (samples: 141442)
INFO:root:Loss: 0.8776 +/- 0.0036
INFO:root:Epoch no. 29 of 500 (samples: 141442)
INFO:root:Loss: 0.8708 +/- 0.0049
INFO:root:Epoch no. 30 of 500 (samples: 141442)
INFO:root:Loss: 0.8654 +/- 0.0044
INFO:root:Epoch no. 31 of 500 (samples: 141442)
INFO:root:Loss: 0.8609 +/- 0.0022
INFO:root:Epoch no. 32 of 500 (samples: 141442)
INFO:root:Loss: 0.8558 +/- 0.0024
INFO:root:Epoch no. 33 of 500 (samples: 141442)
INFO:root:Loss: 0.851 +/- 0.0042
INFO:root:Epoch no. 34 of 500 (samples: 141442)
INFO:root:Loss: 0.8452 +/- 0.0037
INFO:root:Epoch no. 35 of 500 (samples: 141442)
INFO:root:Loss: 0.8405 +/- 0.0046
INFO:root:Epoch no. 36 of 500 (samples: 141442)
INFO:root:Loss: 0.8357 +/- 0.0014
INFO:root:Epoch no. 37 of 500 (samples: 141442)
INFO:root:Loss: 0.8303 +/- 0.0039
INFO:root:Epoch no. 38 of 500 (samples: 141442)
INFO:root:Loss: 0.8269 +/- 0.0036
INFO:root:Epoch no. 39 of 500 (samples: 141442)
INFO:root:Loss: 0.8235 +/- 0.0036
INFO:root:Epoch no. 40 of 500 (samples: 141442)
INFO:root:Loss: 0.8178 +/- 0.0038
INFO:root:Epoch no. 41 of 500 (samples: 141442)
INFO:root:Loss: 0.815 +/- 0.0036
INFO:root:Epoch no. 42 of 500 (samples: 141442)
INFO:root:Loss: 0.8113 +/- 0.0032
INFO:root:Epoch no. 43 of 500 (samples: 141442)
INFO:root:Loss: 0.808 +/- 0.0046
INFO:root:Epoch no. 44 of 500 (samples: 141442)
INFO:root:Loss: 0.8062 +/- 0.0036
INFO:root:Epoch no. 45 of 500 (samples: 141442)
INFO:root:Loss: 0.8011 +/- 0.0032
INFO:root:Epoch no. 46 of 500 (samples: 141442)
INFO:root:Loss: 0.7991 +/- 0.0054
INFO:root:Epoch no. 47 of 500 (samples: 141442)
INFO:root:Loss: 0.7957 +/- 0.0037
INFO:root:Epoch no. 48 of 500 (samples: 141442)
INFO:root:Loss: 0.792 +/- 0.0039
INFO:root:Epoch no. 49 of 500 (samples: 141442)
INFO:root:Loss: 0.7897 +/- 0.0052
INFO:root:Epoch no. 50 of 500 (samples: 141442)
INFO:root:Loss: 0.7873 +/- 0.0029
INFO:root:Epoch no. 51 of 500 (samples: 141442)
INFO:root:Loss: 0.7849 +/- 0.0037
INFO:root:Epoch no. 52 of 500 (samples: 141442)
INFO:root:Loss: 0.7829 +/- 0.0025
INFO:root:Epoch no. 53 of 500 (samples: 141442)
INFO:root:Loss: 0.7795 +/- 0.0028
INFO:root:Epoch no. 54 of 500 (samples: 141442)
INFO:root:Loss: 0.7773 +/- 0.0023
INFO:root:Epoch no. 55 of 500 (samples: 141442)
INFO:root:Loss: 0.7768 +/- 0.0024
INFO:root:Epoch no. 56 of 500 (samples: 141442)
INFO:root:Loss: 0.7736 +/- 0.0036
INFO:root:Epoch no. 57 of 500 (samples: 141442)
INFO:root:Loss: 0.7713 +/- 0.0039
INFO:root:Epoch no. 58 of 500 (samples: 141442)
INFO:root:Loss: 0.769 +/- 0.004
INFO:root:Epoch no. 59 of 500 (samples: 141442)
INFO:root:Loss: 0.7674 +/- 0.0025
INFO:root:Epoch no. 60 of 500 (samples: 141442)
INFO:root:Loss: 0.7655 +/- 0.0022
INFO:root:Epoch no. 61 of 500 (samples: 141442)
INFO:root:Loss: 0.7642 +/- 0.0019
INFO:root:Epoch no. 62 of 500 (samples: 141442)
INFO:root:Loss: 0.7608 +/- 0.0022
INFO:root:Epoch no. 63 of 500 (samples: 141442)
INFO:root:Loss: 0.7594 +/- 0.0027
INFO:root:Epoch no. 64 of 500 (samples: 141442)
INFO:root:Loss: 0.7584 +/- 0.0026
INFO:root:Epoch no. 65 of 500 (samples: 141442)
INFO:root:Loss: 0.7573 +/- 0.0029
INFO:root:Epoch no. 66 of 500 (samples: 141442)
INFO:root:Loss: 0.7537 +/- 0.0028
INFO:root:Epoch no. 67 of 500 (samples: 141442)
INFO:root:Loss: 0.7559 +/- 0.0025
INFO:root:Epoch no. 68 of 500 (samples: 141442)
INFO:root:Loss: 0.7532 +/- 0.0042
INFO:root:Epoch no. 69 of 500 (samples: 141442)
INFO:root:Loss: 0.7513 +/- 0.0054
INFO:root:Epoch no. 70 of 500 (samples: 141442)
INFO:root:Loss: 0.7487 +/- 0.003
INFO:root:Epoch no. 71 of 500 (samples: 141442)
INFO:root:Loss: 0.7478 +/- 0.0041
INFO:root:Epoch no. 72 of 500 (samples: 141442)
INFO:root:Loss: 0.7479 +/- 0.0026
INFO:root:Epoch no. 73 of 500 (samples: 141442)
INFO:root:Loss: 0.746 +/- 0.0026
INFO:root:Epoch no. 74 of 500 (samples: 141442)
INFO:root:Loss: 0.7437 +/- 0.0032
INFO:root:Epoch no. 75 of 500 (samples: 141442)
INFO:root:Loss: 0.7425 +/- 0.0027
INFO:root:Epoch no. 76 of 500 (samples: 141442)
INFO:root:Loss: 0.741 +/- 0.0028
INFO:root:Epoch no. 77 of 500 (samples: 141442)
INFO:root:Loss: 0.7388 +/- 0.0024
INFO:root:Epoch no. 78 of 500 (samples: 141442)
INFO:root:Loss: 0.738 +/- 0.0036
INFO:root:Epoch no. 79 of 500 (samples: 141442)
INFO:root:Loss: 0.7372 +/- 0.0037
INFO:root:Epoch no. 80 of 500 (samples: 141442)
INFO:root:Loss: 0.7357 +/- 0.003
INFO:root:Epoch no. 81 of 500 (samples: 141442)
INFO:root:Loss: 0.7354 +/- 0.0039
INFO:root:Epoch no. 82 of 500 (samples: 141442)
INFO:root:Loss: 0.7345 +/- 0.0025
INFO:root:Epoch no. 83 of 500 (samples: 141442)
INFO:root:Loss: 0.7327 +/- 0.0031
INFO:root:Epoch no. 84 of 500 (samples: 141442)
INFO:root:Loss: 0.7311 +/- 0.004
INFO:root:Epoch no. 85 of 500 (samples: 141442)
INFO:root:Loss: 0.7309 +/- 0.0035
INFO:root:Epoch no. 86 of 500 (samples: 141442)
INFO:root:Loss: 0.7293 +/- 0.002
INFO:root:Epoch no. 87 of 500 (samples: 141442)
INFO:root:Loss: 0.728 +/- 0.0026
INFO:root:Epoch no. 88 of 500 (samples: 141442)
INFO:root:Loss: 0.7271 +/- 0.0027
INFO:root:Epoch no. 89 of 500 (samples: 141442)
INFO:root:Loss: 0.7278 +/- 0.0024
INFO:root:Epoch no. 90 of 500 (samples: 141442)
INFO:root:Loss: 0.7255 +/- 0.0046
INFO:root:Epoch no. 91 of 500 (samples: 141442)
INFO:root:Loss: 0.725 +/- 0.0025
INFO:root:Epoch no. 92 of 500 (samples: 141442)
INFO:root:Loss: 0.7234 +/- 0.004
INFO:root:Epoch no. 93 of 500 (samples: 141442)
INFO:root:Loss: 0.7233 +/- 0.0044
INFO:root:Epoch no. 94 of 500 (samples: 141442)
INFO:root:Loss: 0.7211 +/- 0.0022
INFO:root:Epoch no. 95 of 500 (samples: 141442)
INFO:root:Loss: 0.7206 +/- 0.0025
INFO:root:Epoch no. 96 of 500 (samples: 141442)
INFO:root:Loss: 0.7207 +/- 0.0038
INFO:root:Epoch no. 97 of 500 (samples: 141442)
INFO:root:Loss: 0.719 +/- 0.0036
INFO:root:Epoch no. 98 of 500 (samples: 141442)
INFO:root:Loss: 0.7195 +/- 0.0034
INFO:root:Epoch no. 99 of 500 (samples: 141442)
INFO:root:Loss: 0.7183 +/- 0.0023
INFO:root:Epoch no. 100 of 500 (samples: 141442)
INFO:root:Loss: 0.7168 +/- 0.0035
INFO:root:Epoch no. 101 of 500 (samples: 141442)
INFO:root:Loss: 0.7163 +/- 0.0032
INFO:root:Epoch no. 102 of 500 (samples: 141442)
INFO:root:Loss: 0.7161 +/- 0.0023
INFO:root:Epoch no. 103 of 500 (samples: 141442)
INFO:root:Loss: 0.7149 +/- 0.0028
INFO:root:Epoch no. 104 of 500 (samples: 141442)
INFO:root:Loss: 0.7126 +/- 0.0036
INFO:root:Epoch no. 105 of 500 (samples: 141442)
INFO:root:Loss: 0.7124 +/- 0.0026
INFO:root:Epoch no. 106 of 500 (samples: 141442)
INFO:root:Loss: 0.7122 +/- 0.0039
INFO:root:Epoch no. 107 of 500 (samples: 141442)
INFO:root:Loss: 0.711 +/- 0.0026
INFO:root:Epoch no. 108 of 500 (samples: 141442)
INFO:root:Loss: 0.7111 +/- 0.0044
INFO:root:Epoch no. 109 of 500 (samples: 141442)
INFO:root:Loss: 0.7094 +/- 0.0051
INFO:root:Epoch no. 110 of 500 (samples: 141442)
INFO:root:Loss: 0.7078 +/- 0.0026
INFO:root:Epoch no. 111 of 500 (samples: 141442)
INFO:root:Loss: 0.7079 +/- 0.0039
INFO:root:Epoch no. 112 of 500 (samples: 141442)
INFO:root:Loss: 0.7064 +/- 0.0032
INFO:root:Epoch no. 113 of 500 (samples: 141442)
INFO:root:Loss: 0.7075 +/- 0.0041
INFO:root:Epoch no. 114 of 500 (samples: 141442)
INFO:root:Loss: 0.7057 +/- 0.0042
INFO:root:Epoch no. 115 of 500 (samples: 141442)
INFO:root:Loss: 0.7053 +/- 0.0026
INFO:root:Epoch no. 116 of 500 (samples: 141442)
INFO:root:Loss: 0.7043 +/- 0.0047
INFO:root:Epoch no. 117 of 500 (samples: 141442)
INFO:root:Loss: 0.7029 +/- 0.0037
INFO:root:Epoch no. 118 of 500 (samples: 141442)
INFO:root:Loss: 0.7033 +/- 0.003
INFO:root:Epoch no. 119 of 500 (samples: 141442)
INFO:root:Loss: 0.7014 +/- 0.0021
INFO:root:Epoch no. 120 of 500 (samples: 141442)
INFO:root:Loss: 0.7012 +/- 0.0037
INFO:root:Epoch no. 121 of 500 (samples: 141442)
INFO:root:Loss: 0.7007 +/- 0.0042
INFO:root:Epoch no. 122 of 500 (samples: 141442)
INFO:root:Loss: 0.7005 +/- 0.0042
INFO:root:Epoch no. 123 of 500 (samples: 141442)
INFO:root:Loss: 0.7004 +/- 0.0029
INFO:root:Epoch no. 124 of 500 (samples: 141442)
INFO:root:Loss: 0.7001 +/- 0.0029
INFO:root:Epoch no. 125 of 500 (samples: 141442)
INFO:root:Loss: 0.6975 +/- 0.0036
INFO:root:Epoch no. 126 of 500 (samples: 141442)
INFO:root:Loss: 0.6968 +/- 0.0032
INFO:root:Epoch no. 127 of 500 (samples: 141442)
INFO:root:Loss: 0.6974 +/- 0.0027
INFO:root:Epoch no. 128 of 500 (samples: 141442)
INFO:root:Loss: 0.697 +/- 0.0032
INFO:root:Epoch no. 129 of 500 (samples: 141442)
INFO:root:Loss: 0.697 +/- 0.0019
INFO:root:Epoch no. 130 of 500 (samples: 141442)
INFO:root:Loss: 0.6949 +/- 0.0029
INFO:root:Epoch no. 131 of 500 (samples: 141442)
INFO:root:Loss: 0.6954 +/- 0.0027
INFO:root:Epoch no. 132 of 500 (samples: 141442)
INFO:root:Loss: 0.6932 +/- 0.0041
INFO:root:Epoch no. 133 of 500 (samples: 141442)
INFO:root:Loss: 0.6935 +/- 0.0028
INFO:root:Epoch no. 134 of 500 (samples: 141442)
INFO:root:Loss: 0.6933 +/- 0.0025
INFO:root:Epoch no. 135 of 500 (samples: 141442)
INFO:root:Loss: 0.6919 +/- 0.003
INFO:root:Epoch no. 136 of 500 (samples: 141442)
INFO:root:Loss: 0.6914 +/- 0.0023
INFO:root:Epoch no. 137 of 500 (samples: 141442)
INFO:root:Loss: 0.6918 +/- 0.0029
INFO:root:Epoch no. 138 of 500 (samples: 141442)
INFO:root:Loss: 0.6895 +/- 0.0027
INFO:root:Epoch no. 139 of 500 (samples: 141442)
INFO:root:Loss: 0.6907 +/- 0.0044
INFO:root:Epoch no. 140 of 500 (samples: 141442)
INFO:root:Loss: 0.6884 +/- 0.0048
INFO:root:Epoch no. 141 of 500 (samples: 141442)
INFO:root:Loss: 0.6888 +/- 0.0031
INFO:root:Epoch no. 142 of 500 (samples: 141442)
INFO:root:Loss: 0.6873 +/- 0.0028
INFO:root:Epoch no. 143 of 500 (samples: 141442)
INFO:root:Loss: 0.6865 +/- 0.0034
INFO:root:Epoch no. 144 of 500 (samples: 141442)
INFO:root:Loss: 0.6872 +/- 0.0044
INFO:root:Epoch no. 145 of 500 (samples: 141442)
INFO:root:Loss: 0.6862 +/- 0.0032
INFO:root:Epoch no. 146 of 500 (samples: 141442)
INFO:root:Loss: 0.6865 +/- 0.0017
INFO:root:Epoch no. 147 of 500 (samples: 141442)
INFO:root:Loss: 0.6861 +/- 0.0041
INFO:root:Epoch no. 148 of 500 (samples: 141442)
INFO:root:Loss: 0.6847 +/- 0.0031
INFO:root:Epoch no. 149 of 500 (samples: 141442)
INFO:root:Loss: 0.6837 +/- 0.0046
INFO:root:Epoch no. 150 of 500 (samples: 141442)
INFO:root:Loss: 0.6837 +/- 0.0032
INFO:root:Epoch no. 151 of 500 (samples: 141442)
INFO:root:Loss: 0.6825 +/- 0.0041
INFO:root:Epoch no. 152 of 500 (samples: 141442)
INFO:root:Loss: 0.6821 +/- 0.0028
INFO:root:Epoch no. 153 of 500 (samples: 141442)
INFO:root:Loss: 0.6816 +/- 0.0036
INFO:root:Epoch no. 154 of 500 (samples: 141442)
INFO:root:Loss: 0.6814 +/- 0.0053
INFO:root:Epoch no. 155 of 500 (samples: 141442)
INFO:root:Loss: 0.6806 +/- 0.0013
INFO:root:Epoch no. 156 of 500 (samples: 141442)
INFO:root:Loss: 0.6801 +/- 0.0027
INFO:root:Epoch no. 157 of 500 (samples: 141442)
INFO:root:Loss: 0.6792 +/- 0.0041
INFO:root:Epoch no. 158 of 500 (samples: 141442)
INFO:root:Loss: 0.678 +/- 0.0025
INFO:root:Epoch no. 159 of 500 (samples: 141442)
INFO:root:Loss: 0.6785 +/- 0.0032
INFO:root:Epoch no. 160 of 500 (samples: 141442)
INFO:root:Loss: 0.678 +/- 0.0043
INFO:root:Epoch no. 161 of 500 (samples: 141442)
INFO:root:Loss: 0.6759 +/- 0.0032
INFO:root:Epoch no. 162 of 500 (samples: 141442)
INFO:root:Loss: 0.6768 +/- 0.0024
INFO:root:Epoch no. 163 of 500 (samples: 141442)
INFO:root:Loss: 0.6764 +/- 0.0047
INFO:root:Epoch no. 164 of 500 (samples: 141442)
INFO:root:Loss: 0.6748 +/- 0.0032
INFO:root:Epoch no. 165 of 500 (samples: 141442)
INFO:root:Loss: 0.6754 +/- 0.0028
INFO:root:Epoch no. 166 of 500 (samples: 141442)
INFO:root:Loss: 0.6743 +/- 0.0034
INFO:root:Epoch no. 167 of 500 (samples: 141442)
INFO:root:Loss: 0.6732 +/- 0.0031
INFO:root:Epoch no. 168 of 500 (samples: 141442)
INFO:root:Loss: 0.6728 +/- 0.0019
INFO:root:Epoch no. 169 of 500 (samples: 141442)
INFO:root:Loss: 0.6724 +/- 0.0039
INFO:root:Epoch no. 170 of 500 (samples: 141442)
INFO:root:Loss: 0.6719 +/- 0.0055
INFO:root:Epoch no. 171 of 500 (samples: 141442)
INFO:root:Loss: 0.6715 +/- 0.0032
INFO:root:Epoch no. 172 of 500 (samples: 141442)
INFO:root:Loss: 0.6712 +/- 0.0037
INFO:root:Epoch no. 173 of 500 (samples: 141442)
INFO:root:Loss: 0.6716 +/- 0.0014
INFO:root:Epoch no. 174 of 500 (samples: 141442)
INFO:root:Loss: 0.6694 +/- 0.0027
INFO:root:Epoch no. 175 of 500 (samples: 141442)
INFO:root:Loss: 0.6707 +/- 0.0017
INFO:root:Epoch no. 176 of 500 (samples: 141442)
INFO:root:Loss: 0.6681 +/- 0.0051
INFO:root:Epoch no. 177 of 500 (samples: 141442)
INFO:root:Loss: 0.6686 +/- 0.0029
INFO:root:Epoch no. 178 of 500 (samples: 141442)
INFO:root:Loss: 0.6686 +/- 0.0032
INFO:root:Epoch no. 179 of 500 (samples: 141442)
INFO:root:Loss: 0.6685 +/- 0.0033
INFO:root:Epoch no. 180 of 500 (samples: 141442)
INFO:root:Loss: 0.6673 +/- 0.0031
INFO:root:Epoch no. 181 of 500 (samples: 141442)
INFO:root:Loss: 0.6665 +/- 0.0039
INFO:root:Epoch no. 182 of 500 (samples: 141442)
INFO:root:Loss: 0.6659 +/- 0.0036
INFO:root:Epoch no. 183 of 500 (samples: 141442)
INFO:root:Loss: 0.6671 +/- 0.0041
INFO:root:Epoch no. 184 of 500 (samples: 141442)
INFO:root:Loss: 0.6667 +/- 0.0029
INFO:root:Epoch no. 185 of 500 (samples: 141442)
INFO:root:Loss: 0.6647 +/- 0.002
INFO:root:Epoch no. 186 of 500 (samples: 141442)
INFO:root:Loss: 0.6647 +/- 0.0023
INFO:root:Epoch no. 187 of 500 (samples: 141442)
INFO:root:Loss: 0.6633 +/- 0.0017
INFO:root:Epoch no. 188 of 500 (samples: 141442)
INFO:root:Loss: 0.6627 +/- 0.0031
INFO:root:Epoch no. 189 of 500 (samples: 141442)
INFO:root:Loss: 0.6625 +/- 0.0029
INFO:root:Epoch no. 190 of 500 (samples: 141442)
INFO:root:Loss: 0.6626 +/- 0.0027
INFO:root:Epoch no. 191 of 500 (samples: 141442)
INFO:root:Loss: 0.662 +/- 0.0027
INFO:root:Epoch no. 192 of 500 (samples: 141442)
INFO:root:Loss: 0.6612 +/- 0.0037
INFO:root:Epoch no. 193 of 500 (samples: 141442)
INFO:root:Loss: 0.6604 +/- 0.0029
INFO:root:Epoch no. 194 of 500 (samples: 141442)
INFO:root:Loss: 0.6594 +/- 0.0024
INFO:root:Epoch no. 195 of 500 (samples: 141442)
INFO:root:Loss: 0.6584 +/- 0.0029
INFO:root:Epoch no. 196 of 500 (samples: 141442)
INFO:root:Loss: 0.6596 +/- 0.0031
INFO:root:Epoch no. 197 of 500 (samples: 141442)
INFO:root:Loss: 0.6585 +/- 0.0023
INFO:root:Epoch no. 198 of 500 (samples: 141442)
INFO:root:Loss: 0.6569 +/- 0.0031
INFO:root:Epoch no. 199 of 500 (samples: 141442)
INFO:root:Loss: 0.6577 +/- 0.0047
INFO:root:Epoch no. 200 of 500 (samples: 141442)
INFO:root:Loss: 0.6575 +/- 0.0016
INFO:root:Epoch no. 201 of 500 (samples: 141442)
INFO:root:Loss: 0.6562 +/- 0.0035
INFO:root:Epoch no. 202 of 500 (samples: 141442)
INFO:root:Loss: 0.6564 +/- 0.0027
INFO:root:Epoch no. 203 of 500 (samples: 141442)
INFO:root:Loss: 0.6563 +/- 0.0029
INFO:root:Epoch no. 204 of 500 (samples: 141442)
INFO:root:Loss: 0.6558 +/- 0.0034
INFO:root:Epoch no. 205 of 500 (samples: 141442)
INFO:root:Loss: 0.6537 +/- 0.0036
INFO:root:Epoch no. 206 of 500 (samples: 141442)
INFO:root:Loss: 0.6546 +/- 0.003
INFO:root:Epoch no. 207 of 500 (samples: 141442)
INFO:root:Loss: 0.6543 +/- 0.0024
INFO:root:Epoch no. 208 of 500 (samples: 141442)
INFO:root:Loss: 0.6528 +/- 0.0026
INFO:root:Epoch no. 209 of 500 (samples: 141442)
INFO:root:Loss: 0.6526 +/- 0.0027
INFO:root:Epoch no. 210 of 500 (samples: 141442)
INFO:root:Loss: 0.6529 +/- 0.0026
INFO:root:Epoch no. 211 of 500 (samples: 141442)
INFO:root:Loss: 0.6504 +/- 0.0041
INFO:root:Epoch no. 212 of 500 (samples: 141442)
INFO:root:Loss: 0.6518 +/- 0.0039
INFO:root:Epoch no. 213 of 500 (samples: 141442)
INFO:root:Loss: 0.6501 +/- 0.0029
INFO:root:Epoch no. 214 of 500 (samples: 141442)
INFO:root:Loss: 0.6508 +/- 0.003
INFO:root:Epoch no. 215 of 500 (samples: 141442)
INFO:root:Loss: 0.6502 +/- 0.002
INFO:root:Epoch no. 216 of 500 (samples: 141442)
INFO:root:Loss: 0.6492 +/- 0.0033
INFO:root:Epoch no. 217 of 500 (samples: 141442)
INFO:root:Loss: 0.6483 +/- 0.004
INFO:root:Epoch no. 218 of 500 (samples: 141442)
INFO:root:Loss: 0.648 +/- 0.0033
INFO:root:Epoch no. 219 of 500 (samples: 141442)
INFO:root:Loss: 0.6469 +/- 0.0033
INFO:root:Epoch no. 220 of 500 (samples: 141442)
INFO:root:Loss: 0.6489 +/- 0.0031
INFO:root:Epoch no. 221 of 500 (samples: 141442)
INFO:root:Loss: 0.646 +/- 0.0031
INFO:root:Epoch no. 222 of 500 (samples: 141442)
INFO:root:Loss: 0.6468 +/- 0.0023
INFO:root:Epoch no. 223 of 500 (samples: 141442)
INFO:root:Loss: 0.6444 +/- 0.0032
INFO:root:Epoch no. 224 of 500 (samples: 141442)
INFO:root:Loss: 0.646 +/- 0.0033
INFO:root:Epoch no. 225 of 500 (samples: 141442)
INFO:root:Loss: 0.6455 +/- 0.0027
INFO:root:Epoch no. 226 of 500 (samples: 141442)
INFO:root:Loss: 0.6431 +/- 0.0027
INFO:root:Epoch no. 227 of 500 (samples: 141442)
INFO:root:Loss: 0.644 +/- 0.0023
INFO:root:Epoch no. 228 of 500 (samples: 141442)
INFO:root:Loss: 0.6443 +/- 0.0035
INFO:root:Epoch no. 229 of 500 (samples: 141442)
INFO:root:Loss: 0.6424 +/- 0.0022
INFO:root:Epoch no. 230 of 500 (samples: 141442)
INFO:root:Loss: 0.6407 +/- 0.0025
INFO:root:Epoch no. 231 of 500 (samples: 141442)
INFO:root:Loss: 0.6426 +/- 0.0027
INFO:root:Epoch no. 232 of 500 (samples: 141442)
INFO:root:Loss: 0.642 +/- 0.0043
INFO:root:Epoch no. 233 of 500 (samples: 141442)
INFO:root:Loss: 0.6415 +/- 0.0024
INFO:root:Epoch no. 234 of 500 (samples: 141442)
INFO:root:Loss: 0.6404 +/- 0.0022
INFO:root:Epoch no. 235 of 500 (samples: 141442)
INFO:root:Loss: 0.6404 +/- 0.0037
INFO:root:Epoch no. 236 of 500 (samples: 141442)
INFO:root:Loss: 0.6392 +/- 0.0025
INFO:root:Epoch no. 237 of 500 (samples: 141442)
INFO:root:Loss: 0.6403 +/- 0.005
INFO:root:Epoch no. 238 of 500 (samples: 141442)
INFO:root:Loss: 0.6384 +/- 0.0026
INFO:root:Epoch no. 239 of 500 (samples: 141442)
INFO:root:Loss: 0.6391 +/- 0.0031
INFO:root:Epoch no. 240 of 500 (samples: 141442)
INFO:root:Loss: 0.6381 +/- 0.0021
INFO:root:Epoch no. 241 of 500 (samples: 141442)
INFO:root:Loss: 0.6378 +/- 0.0011
INFO:root:Epoch no. 242 of 500 (samples: 141442)
INFO:root:Loss: 0.6367 +/- 0.0036
INFO:root:Epoch no. 243 of 500 (samples: 141442)
INFO:root:Loss: 0.6375 +/- 0.0012
INFO:root:Epoch no. 244 of 500 (samples: 141442)
INFO:root:Loss: 0.636 +/- 0.003
INFO:root:Epoch no. 245 of 500 (samples: 141442)
INFO:root:Loss: 0.6364 +/- 0.0038
INFO:root:Epoch no. 246 of 500 (samples: 141442)
INFO:root:Loss: 0.6352 +/- 0.0019
INFO:root:Epoch no. 247 of 500 (samples: 141442)
INFO:root:Loss: 0.6335 +/- 0.0018
INFO:root:Epoch no. 248 of 500 (samples: 141442)
INFO:root:Loss: 0.6333 +/- 0.0025
INFO:root:Epoch no. 249 of 500 (samples: 141442)
INFO:root:Loss: 0.6338 +/- 0.004
INFO:root:Epoch no. 250 of 500 (samples: 141442)
INFO:root:Loss: 0.633 +/- 0.0031
INFO:root:Epoch no. 251 of 500 (samples: 141442)
INFO:root:Loss: 0.6331 +/- 0.0028
INFO:root:Epoch no. 252 of 500 (samples: 141442)
INFO:root:Loss: 0.6321 +/- 0.0026
INFO:root:Epoch no. 253 of 500 (samples: 141442)
INFO:root:Loss: 0.6313 +/- 0.0046
INFO:root:Epoch no. 254 of 500 (samples: 141442)
Traceback (most recent call last):
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/hyper-cli.py", line 324, in <module>
    main(sys.argv[1:])
  File "./bin/hyper-cli.py", line 293, in main
    visualize=is_visualize)
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/learning/core.py", line 185, in pairwise_training
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/models.py", line 409, in fit
    sample_weight=sample_weight)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/training.py", line 1052, in fit
    callback_metrics=callback_metrics)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/training.py", line 790, in _fit_loop
    outs = f(ins_batch)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/backend/theano_backend.py", line 518, in __call__
    return self.function(*inputs)
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/usr/local/lib/python3.4/dist-packages/theano/gof/link.py", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/usr/local/lib/python3.4/dist-packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
MemoryError: 
Apply node that caused the error: AdvancedSubtensor1(embedding_1_W, Reshape{1}.0)
Toposort index: 19
Inputs types: [TensorType(float32, matrix), TensorType(int32, vector)]
Inputs shapes: [(19, 10000), (42435,)]
Inputs strides: [(40000, 4), (4,)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Reshape{3}(AdvancedSubtensor1.0, MakeVector{dtype='int64'}.0)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/learning/core.py", line 56, in pairwise_training
    predicate_encoder.add(predicate_embedding_layer)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/models.py", line 114, in add
    layer.create_input_layer(batch_input_shape, input_dtype)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 341, in create_input_layer
    self(x)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 485, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 543, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 148, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/layers/embeddings.py", line 135, in call
    out = K.gather(W, x)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/backend/theano_backend.py", line 166, in gather
    return reference[indices]

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
