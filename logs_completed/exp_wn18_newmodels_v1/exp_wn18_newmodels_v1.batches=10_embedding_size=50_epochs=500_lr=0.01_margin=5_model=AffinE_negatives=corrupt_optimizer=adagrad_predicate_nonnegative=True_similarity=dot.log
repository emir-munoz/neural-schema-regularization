Using Theano backend.
INFO:root:Acquiring data/wn18/wordnet-mlj12-train.txt ..
INFO:root:Acquiring data/wn18/wordnet-mlj12-valid.txt ..
INFO:root:Acquiring data/wn18/wordnet-mlj12-test.txt ..
INFO:root:Samples: 141442, no. batches: 10 -> batch size: 14145
INFO:root:Epoch no. 1 of 500 (samples: 141442)
INFO:root:Loss: 3.3191 +/- 0.0088
INFO:root:Epoch no. 2 of 500 (samples: 141442)
INFO:root:Loss: 3.2706 +/- 0.0137
INFO:root:Epoch no. 3 of 500 (samples: 141442)
INFO:root:Loss: 3.1938 +/- 0.0213
INFO:root:Epoch no. 4 of 500 (samples: 141442)
INFO:root:Loss: 3.0884 +/- 0.0265
INFO:root:Epoch no. 5 of 500 (samples: 141442)
INFO:root:Loss: 2.9586 +/- 0.036
INFO:root:Epoch no. 6 of 500 (samples: 141442)
INFO:root:Loss: 2.8117 +/- 0.0356
INFO:root:Epoch no. 7 of 500 (samples: 141442)
INFO:root:Loss: 2.6515 +/- 0.0364
INFO:root:Epoch no. 8 of 500 (samples: 141442)
INFO:root:Loss: 2.4833 +/- 0.0367
INFO:root:Epoch no. 9 of 500 (samples: 141442)
INFO:root:Loss: 2.3218 +/- 0.0343
INFO:root:Epoch no. 10 of 500 (samples: 141442)
INFO:root:Loss: 2.1674 +/- 0.0319
INFO:root:Epoch no. 11 of 500 (samples: 141442)
INFO:root:Loss: 2.0362 +/- 0.0288
INFO:root:Epoch no. 12 of 500 (samples: 141442)
INFO:root:Loss: 1.9178 +/- 0.0186
INFO:root:Epoch no. 13 of 500 (samples: 141442)
INFO:root:Loss: 1.8202 +/- 0.0181
INFO:root:Epoch no. 14 of 500 (samples: 141442)
INFO:root:Loss: 1.7363 +/- 0.0183
INFO:root:Epoch no. 15 of 500 (samples: 141442)
INFO:root:Loss: 1.6629 +/- 0.015
INFO:root:Epoch no. 16 of 500 (samples: 141442)
INFO:root:Loss: 1.599 +/- 0.0184
INFO:root:Epoch no. 17 of 500 (samples: 141442)
INFO:root:Loss: 1.5404 +/- 0.0139
INFO:root:Epoch no. 18 of 500 (samples: 141442)
INFO:root:Loss: 1.4921 +/- 0.0102
INFO:root:Epoch no. 19 of 500 (samples: 141442)
INFO:root:Loss: 1.452 +/- 0.0124
INFO:root:Epoch no. 20 of 500 (samples: 141442)
INFO:root:Loss: 1.4142 +/- 0.0123
INFO:root:Epoch no. 21 of 500 (samples: 141442)
INFO:root:Loss: 1.3784 +/- 0.0098
INFO:root:Epoch no. 22 of 500 (samples: 141442)
INFO:root:Loss: 1.3483 +/- 0.0115
INFO:root:Epoch no. 23 of 500 (samples: 141442)
INFO:root:Loss: 1.3189 +/- 0.0081
INFO:root:Epoch no. 24 of 500 (samples: 141442)
INFO:root:Loss: 1.2924 +/- 0.0116
INFO:root:Epoch no. 25 of 500 (samples: 141442)
INFO:root:Loss: 1.2639 +/- 0.0099
INFO:root:Epoch no. 26 of 500 (samples: 141442)
INFO:root:Loss: 1.2444 +/- 0.0067
INFO:root:Epoch no. 27 of 500 (samples: 141442)
INFO:root:Loss: 1.2261 +/- 0.0099
INFO:root:Epoch no. 28 of 500 (samples: 141442)
INFO:root:Loss: 1.2037 +/- 0.0098
INFO:root:Epoch no. 29 of 500 (samples: 141442)
INFO:root:Loss: 1.1887 +/- 0.0116
INFO:root:Epoch no. 30 of 500 (samples: 141442)
INFO:root:Loss: 1.1713 +/- 0.0097
INFO:root:Epoch no. 31 of 500 (samples: 141442)
INFO:root:Loss: 1.1556 +/- 0.0135
INFO:root:Epoch no. 32 of 500 (samples: 141442)
INFO:root:Loss: 1.1413 +/- 0.0148
INFO:root:Epoch no. 33 of 500 (samples: 141442)
INFO:root:Loss: 1.1279 +/- 0.0087
INFO:root:Epoch no. 34 of 500 (samples: 141442)
INFO:root:Loss: 1.114 +/- 0.0089
INFO:root:Epoch no. 35 of 500 (samples: 141442)
INFO:root:Loss: 1.0945 +/- 0.0087
INFO:root:Epoch no. 36 of 500 (samples: 141442)
INFO:root:Loss: 1.0844 +/- 0.0088
INFO:root:Epoch no. 37 of 500 (samples: 141442)
INFO:root:Loss: 1.073 +/- 0.0086
INFO:root:Epoch no. 38 of 500 (samples: 141442)
INFO:root:Loss: 1.065 +/- 0.0135
INFO:root:Epoch no. 39 of 500 (samples: 141442)
INFO:root:Loss: 1.055 +/- 0.0081
INFO:root:Epoch no. 40 of 500 (samples: 141442)
INFO:root:Loss: 1.0354 +/- 0.013
INFO:root:Epoch no. 41 of 500 (samples: 141442)
INFO:root:Loss: 1.0265 +/- 0.0068
INFO:root:Epoch no. 42 of 500 (samples: 141442)
INFO:root:Loss: 1.0196 +/- 0.0109
INFO:root:Epoch no. 43 of 500 (samples: 141442)
INFO:root:Loss: 1.0134 +/- 0.0072
INFO:root:Epoch no. 44 of 500 (samples: 141442)
INFO:root:Loss: 0.9995 +/- 0.0071
INFO:root:Epoch no. 45 of 500 (samples: 141442)
INFO:root:Loss: 0.9893 +/- 0.0065
INFO:root:Epoch no. 46 of 500 (samples: 141442)
INFO:root:Loss: 0.9835 +/- 0.0063
INFO:root:Epoch no. 47 of 500 (samples: 141442)
INFO:root:Loss: 0.9752 +/- 0.0095
INFO:root:Epoch no. 48 of 500 (samples: 141442)
INFO:root:Loss: 0.9662 +/- 0.0109
INFO:root:Epoch no. 49 of 500 (samples: 141442)
INFO:root:Loss: 0.9603 +/- 0.0094
INFO:root:Epoch no. 50 of 500 (samples: 141442)
INFO:root:Loss: 0.9535 +/- 0.0096
INFO:root:Epoch no. 51 of 500 (samples: 141442)
INFO:root:Loss: 0.9464 +/- 0.0114
INFO:root:Epoch no. 52 of 500 (samples: 141442)
INFO:root:Loss: 0.9381 +/- 0.0093
INFO:root:Epoch no. 53 of 500 (samples: 141442)
INFO:root:Loss: 0.9322 +/- 0.0074
INFO:root:Epoch no. 54 of 500 (samples: 141442)
INFO:root:Loss: 0.9228 +/- 0.0092
INFO:root:Epoch no. 55 of 500 (samples: 141442)
INFO:root:Loss: 0.9198 +/- 0.0123
INFO:root:Epoch no. 56 of 500 (samples: 141442)
INFO:root:Loss: 0.9109 +/- 0.0096
INFO:root:Epoch no. 57 of 500 (samples: 141442)
INFO:root:Loss: 0.9042 +/- 0.0092
INFO:root:Epoch no. 58 of 500 (samples: 141442)
INFO:root:Loss: 0.9012 +/- 0.0109
INFO:root:Epoch no. 59 of 500 (samples: 141442)
INFO:root:Loss: 0.8959 +/- 0.0063
INFO:root:Epoch no. 60 of 500 (samples: 141442)
INFO:root:Loss: 0.8856 +/- 0.0095
INFO:root:Epoch no. 61 of 500 (samples: 141442)
INFO:root:Loss: 0.8846 +/- 0.0104
INFO:root:Epoch no. 62 of 500 (samples: 141442)
INFO:root:Loss: 0.881 +/- 0.005
INFO:root:Epoch no. 63 of 500 (samples: 141442)
INFO:root:Loss: 0.8705 +/- 0.0118
INFO:root:Epoch no. 64 of 500 (samples: 141442)
INFO:root:Loss: 0.8649 +/- 0.0052
INFO:root:Epoch no. 65 of 500 (samples: 141442)
INFO:root:Loss: 0.8614 +/- 0.009
INFO:root:Epoch no. 66 of 500 (samples: 141442)
INFO:root:Loss: 0.8549 +/- 0.0111
INFO:root:Epoch no. 67 of 500 (samples: 141442)
INFO:root:Loss: 0.8535 +/- 0.0106
INFO:root:Epoch no. 68 of 500 (samples: 141442)
INFO:root:Loss: 0.8452 +/- 0.012
INFO:root:Epoch no. 69 of 500 (samples: 141442)
INFO:root:Loss: 0.8392 +/- 0.0089
INFO:root:Epoch no. 70 of 500 (samples: 141442)
INFO:root:Loss: 0.8391 +/- 0.0127
INFO:root:Epoch no. 71 of 500 (samples: 141442)
INFO:root:Loss: 0.8305 +/- 0.0058
INFO:root:Epoch no. 72 of 500 (samples: 141442)
INFO:root:Loss: 0.8317 +/- 0.0097
INFO:root:Epoch no. 73 of 500 (samples: 141442)
INFO:root:Loss: 0.8247 +/- 0.0079
INFO:root:Epoch no. 74 of 500 (samples: 141442)
INFO:root:Loss: 0.8212 +/- 0.0054
INFO:root:Epoch no. 75 of 500 (samples: 141442)
INFO:root:Loss: 0.8161 +/- 0.006
INFO:root:Epoch no. 76 of 500 (samples: 141442)
INFO:root:Loss: 0.8089 +/- 0.01
INFO:root:Epoch no. 77 of 500 (samples: 141442)
INFO:root:Loss: 0.8067 +/- 0.0057
INFO:root:Epoch no. 78 of 500 (samples: 141442)
INFO:root:Loss: 0.8014 +/- 0.0057
INFO:root:Epoch no. 79 of 500 (samples: 141442)
INFO:root:Loss: 0.7995 +/- 0.0101
INFO:root:Epoch no. 80 of 500 (samples: 141442)
INFO:root:Loss: 0.7931 +/- 0.0089
INFO:root:Epoch no. 81 of 500 (samples: 141442)
INFO:root:Loss: 0.7919 +/- 0.0065
INFO:root:Epoch no. 82 of 500 (samples: 141442)
INFO:root:Loss: 0.7881 +/- 0.0085
INFO:root:Epoch no. 83 of 500 (samples: 141442)
INFO:root:Loss: 0.7895 +/- 0.0056
INFO:root:Epoch no. 84 of 500 (samples: 141442)
INFO:root:Loss: 0.7791 +/- 0.0075
INFO:root:Epoch no. 85 of 500 (samples: 141442)
INFO:root:Loss: 0.778 +/- 0.0101
INFO:root:Epoch no. 86 of 500 (samples: 141442)
INFO:root:Loss: 0.7736 +/- 0.0093
INFO:root:Epoch no. 87 of 500 (samples: 141442)
INFO:root:Loss: 0.7737 +/- 0.0096
INFO:root:Epoch no. 88 of 500 (samples: 141442)
INFO:root:Loss: 0.7701 +/- 0.0071
INFO:root:Epoch no. 89 of 500 (samples: 141442)
INFO:root:Loss: 0.7657 +/- 0.009
INFO:root:Epoch no. 90 of 500 (samples: 141442)
INFO:root:Loss: 0.7605 +/- 0.0084
INFO:root:Epoch no. 91 of 500 (samples: 141442)
INFO:root:Loss: 0.7577 +/- 0.0076
INFO:root:Epoch no. 92 of 500 (samples: 141442)
INFO:root:Loss: 0.7518 +/- 0.0069
INFO:root:Epoch no. 93 of 500 (samples: 141442)
INFO:root:Loss: 0.7517 +/- 0.0079
INFO:root:Epoch no. 94 of 500 (samples: 141442)
INFO:root:Loss: 0.7455 +/- 0.0098
INFO:root:Epoch no. 95 of 500 (samples: 141442)
INFO:root:Loss: 0.7411 +/- 0.0062
INFO:root:Epoch no. 96 of 500 (samples: 141442)
INFO:root:Loss: 0.7433 +/- 0.0064
INFO:root:Epoch no. 97 of 500 (samples: 141442)
INFO:root:Loss: 0.7344 +/- 0.009
INFO:root:Epoch no. 98 of 500 (samples: 141442)
INFO:root:Loss: 0.7349 +/- 0.0116
INFO:root:Epoch no. 99 of 500 (samples: 141442)
INFO:root:Loss: 0.7327 +/- 0.0109
INFO:root:Epoch no. 100 of 500 (samples: 141442)
INFO:root:Loss: 0.7318 +/- 0.0066
INFO:root:Epoch no. 101 of 500 (samples: 141442)
INFO:root:Loss: 0.7256 +/- 0.0075
INFO:root:Epoch no. 102 of 500 (samples: 141442)
INFO:root:Loss: 0.7248 +/- 0.0093
INFO:root:Epoch no. 103 of 500 (samples: 141442)
INFO:root:Loss: 0.7236 +/- 0.0056
INFO:root:Epoch no. 104 of 500 (samples: 141442)
INFO:root:Loss: 0.7171 +/- 0.0106
INFO:root:Epoch no. 105 of 500 (samples: 141442)
INFO:root:Loss: 0.7185 +/- 0.0103
INFO:root:Epoch no. 106 of 500 (samples: 141442)
INFO:root:Loss: 0.7135 +/- 0.0083
INFO:root:Epoch no. 107 of 500 (samples: 141442)
INFO:root:Loss: 0.7116 +/- 0.0124
INFO:root:Epoch no. 108 of 500 (samples: 141442)
INFO:root:Loss: 0.7067 +/- 0.0071
INFO:root:Epoch no. 109 of 500 (samples: 141442)
INFO:root:Loss: 0.7009 +/- 0.0085
INFO:root:Epoch no. 110 of 500 (samples: 141442)
INFO:root:Loss: 0.7087 +/- 0.007
INFO:root:Epoch no. 111 of 500 (samples: 141442)
INFO:root:Loss: 0.7025 +/- 0.009
INFO:root:Epoch no. 112 of 500 (samples: 141442)
INFO:root:Loss: 0.6994 +/- 0.004
INFO:root:Epoch no. 113 of 500 (samples: 141442)
INFO:root:Loss: 0.7003 +/- 0.007
INFO:root:Epoch no. 114 of 500 (samples: 141442)
INFO:root:Loss: 0.6957 +/- 0.0073
INFO:root:Epoch no. 115 of 500 (samples: 141442)
INFO:root:Loss: 0.6935 +/- 0.0069
INFO:root:Epoch no. 116 of 500 (samples: 141442)
INFO:root:Loss: 0.6934 +/- 0.0072
INFO:root:Epoch no. 117 of 500 (samples: 141442)
INFO:root:Loss: 0.6872 +/- 0.0101
INFO:root:Epoch no. 118 of 500 (samples: 141442)
INFO:root:Loss: 0.6852 +/- 0.0073
INFO:root:Epoch no. 119 of 500 (samples: 141442)
INFO:root:Loss: 0.6837 +/- 0.0059
INFO:root:Epoch no. 120 of 500 (samples: 141442)
INFO:root:Loss: 0.6831 +/- 0.0098
INFO:root:Epoch no. 121 of 500 (samples: 141442)
INFO:root:Loss: 0.6823 +/- 0.0081
INFO:root:Epoch no. 122 of 500 (samples: 141442)
INFO:root:Loss: 0.6784 +/- 0.0067
INFO:root:Epoch no. 123 of 500 (samples: 141442)
INFO:root:Loss: 0.6729 +/- 0.0114
INFO:root:Epoch no. 124 of 500 (samples: 141442)
INFO:root:Loss: 0.676 +/- 0.0072
INFO:root:Epoch no. 125 of 500 (samples: 141442)
INFO:root:Loss: 0.6754 +/- 0.0076
INFO:root:Epoch no. 126 of 500 (samples: 141442)
INFO:root:Loss: 0.6684 +/- 0.0049
INFO:root:Epoch no. 127 of 500 (samples: 141442)
INFO:root:Loss: 0.6702 +/- 0.0058
INFO:root:Epoch no. 128 of 500 (samples: 141442)
INFO:root:Loss: 0.6693 +/- 0.0065
INFO:root:Epoch no. 129 of 500 (samples: 141442)
INFO:root:Loss: 0.6615 +/- 0.0069
INFO:root:Epoch no. 130 of 500 (samples: 141442)
INFO:root:Loss: 0.6603 +/- 0.009
INFO:root:Epoch no. 131 of 500 (samples: 141442)
INFO:root:Loss: 0.6568 +/- 0.0063
INFO:root:Epoch no. 132 of 500 (samples: 141442)
INFO:root:Loss: 0.6567 +/- 0.0065
INFO:root:Epoch no. 133 of 500 (samples: 141442)
INFO:root:Loss: 0.6577 +/- 0.0078
INFO:root:Epoch no. 134 of 500 (samples: 141442)
INFO:root:Loss: 0.6511 +/- 0.008
INFO:root:Epoch no. 135 of 500 (samples: 141442)
INFO:root:Loss: 0.6482 +/- 0.0104
INFO:root:Epoch no. 136 of 500 (samples: 141442)
INFO:root:Loss: 0.6504 +/- 0.0069
INFO:root:Epoch no. 137 of 500 (samples: 141442)
INFO:root:Loss: 0.6445 +/- 0.0048
INFO:root:Epoch no. 138 of 500 (samples: 141442)
INFO:root:Loss: 0.6463 +/- 0.0085
INFO:root:Epoch no. 139 of 500 (samples: 141442)
INFO:root:Loss: 0.6453 +/- 0.0055
INFO:root:Epoch no. 140 of 500 (samples: 141442)
INFO:root:Loss: 0.6395 +/- 0.0106
INFO:root:Epoch no. 141 of 500 (samples: 141442)
INFO:root:Loss: 0.6429 +/- 0.0056
INFO:root:Epoch no. 142 of 500 (samples: 141442)
INFO:root:Loss: 0.6396 +/- 0.006
INFO:root:Epoch no. 143 of 500 (samples: 141442)
INFO:root:Loss: 0.6359 +/- 0.0077
INFO:root:Epoch no. 144 of 500 (samples: 141442)
INFO:root:Loss: 0.6377 +/- 0.0067
INFO:root:Epoch no. 145 of 500 (samples: 141442)
INFO:root:Loss: 0.6328 +/- 0.0096
INFO:root:Epoch no. 146 of 500 (samples: 141442)
INFO:root:Loss: 0.6312 +/- 0.0106
INFO:root:Epoch no. 147 of 500 (samples: 141442)
INFO:root:Loss: 0.6312 +/- 0.0096
INFO:root:Epoch no. 148 of 500 (samples: 141442)
INFO:root:Loss: 0.6262 +/- 0.0083
INFO:root:Epoch no. 149 of 500 (samples: 141442)
INFO:root:Loss: 0.6267 +/- 0.0058
INFO:root:Epoch no. 150 of 500 (samples: 141442)
INFO:root:Loss: 0.6242 +/- 0.0069
INFO:root:Epoch no. 151 of 500 (samples: 141442)
INFO:root:Loss: 0.624 +/- 0.0047
INFO:root:Epoch no. 152 of 500 (samples: 141442)
INFO:root:Loss: 0.6207 +/- 0.0074
INFO:root:Epoch no. 153 of 500 (samples: 141442)
INFO:root:Loss: 0.624 +/- 0.0046
INFO:root:Epoch no. 154 of 500 (samples: 141442)
INFO:root:Loss: 0.6184 +/- 0.0075
INFO:root:Epoch no. 155 of 500 (samples: 141442)
INFO:root:Loss: 0.6188 +/- 0.011
INFO:root:Epoch no. 156 of 500 (samples: 141442)
INFO:root:Loss: 0.6191 +/- 0.0069
INFO:root:Epoch no. 157 of 500 (samples: 141442)
INFO:root:Loss: 0.6149 +/- 0.0039
INFO:root:Epoch no. 158 of 500 (samples: 141442)
INFO:root:Loss: 0.612 +/- 0.0072
INFO:root:Epoch no. 159 of 500 (samples: 141442)
INFO:root:Loss: 0.6122 +/- 0.0106
INFO:root:Epoch no. 160 of 500 (samples: 141442)
INFO:root:Loss: 0.606 +/- 0.0066
INFO:root:Epoch no. 161 of 500 (samples: 141442)
INFO:root:Loss: 0.6062 +/- 0.0089
INFO:root:Epoch no. 162 of 500 (samples: 141442)
INFO:root:Loss: 0.6043 +/- 0.0062
INFO:root:Epoch no. 163 of 500 (samples: 141442)
INFO:root:Loss: 0.6027 +/- 0.0071
INFO:root:Epoch no. 164 of 500 (samples: 141442)
INFO:root:Loss: 0.5997 +/- 0.0082
INFO:root:Epoch no. 165 of 500 (samples: 141442)
INFO:root:Loss: 0.6012 +/- 0.0062
INFO:root:Epoch no. 166 of 500 (samples: 141442)
INFO:root:Loss: 0.5998 +/- 0.0042
INFO:root:Epoch no. 167 of 500 (samples: 141442)
INFO:root:Loss: 0.6014 +/- 0.0057
INFO:root:Epoch no. 168 of 500 (samples: 141442)
INFO:root:Loss: 0.5965 +/- 0.0081
INFO:root:Epoch no. 169 of 500 (samples: 141442)
INFO:root:Loss: 0.599 +/- 0.0074
INFO:root:Epoch no. 170 of 500 (samples: 141442)
INFO:root:Loss: 0.5967 +/- 0.0077
INFO:root:Epoch no. 171 of 500 (samples: 141442)
INFO:root:Loss: 0.5935 +/- 0.0088
INFO:root:Epoch no. 172 of 500 (samples: 141442)
INFO:root:Loss: 0.5934 +/- 0.003
INFO:root:Epoch no. 173 of 500 (samples: 141442)
INFO:root:Loss: 0.5929 +/- 0.0049
INFO:root:Epoch no. 174 of 500 (samples: 141442)
INFO:root:Loss: 0.5872 +/- 0.0079
INFO:root:Epoch no. 175 of 500 (samples: 141442)
INFO:root:Loss: 0.588 +/- 0.0058
INFO:root:Epoch no. 176 of 500 (samples: 141442)
INFO:root:Loss: 0.5881 +/- 0.0084
INFO:root:Epoch no. 177 of 500 (samples: 141442)
INFO:root:Loss: 0.5857 +/- 0.0072
INFO:root:Epoch no. 178 of 500 (samples: 141442)
INFO:root:Loss: 0.5831 +/- 0.0047
INFO:root:Epoch no. 179 of 500 (samples: 141442)
INFO:root:Loss: 0.5862 +/- 0.0086
INFO:root:Epoch no. 180 of 500 (samples: 141442)
INFO:root:Loss: 0.5825 +/- 0.0065
INFO:root:Epoch no. 181 of 500 (samples: 141442)
INFO:root:Loss: 0.5839 +/- 0.0095
INFO:root:Epoch no. 182 of 500 (samples: 141442)
INFO:root:Loss: 0.5738 +/- 0.0082
INFO:root:Epoch no. 183 of 500 (samples: 141442)
INFO:root:Loss: 0.5798 +/- 0.0046
INFO:root:Epoch no. 184 of 500 (samples: 141442)
INFO:root:Loss: 0.5791 +/- 0.009
INFO:root:Epoch no. 185 of 500 (samples: 141442)
INFO:root:Loss: 0.5765 +/- 0.0083
INFO:root:Epoch no. 186 of 500 (samples: 141442)
INFO:root:Loss: 0.5749 +/- 0.0083
INFO:root:Epoch no. 187 of 500 (samples: 141442)
INFO:root:Loss: 0.5729 +/- 0.0096
INFO:root:Epoch no. 188 of 500 (samples: 141442)
INFO:root:Loss: 0.5756 +/- 0.0046
INFO:root:Epoch no. 189 of 500 (samples: 141442)
INFO:root:Loss: 0.5725 +/- 0.0075
INFO:root:Epoch no. 190 of 500 (samples: 141442)
INFO:root:Loss: 0.5709 +/- 0.0095
INFO:root:Epoch no. 191 of 500 (samples: 141442)
INFO:root:Loss: 0.5667 +/- 0.0087
INFO:root:Epoch no. 192 of 500 (samples: 141442)
INFO:root:Loss: 0.5661 +/- 0.0071
INFO:root:Epoch no. 193 of 500 (samples: 141442)
INFO:root:Loss: 0.564 +/- 0.0061
INFO:root:Epoch no. 194 of 500 (samples: 141442)
INFO:root:Loss: 0.5623 +/- 0.0093
INFO:root:Epoch no. 195 of 500 (samples: 141442)
INFO:root:Loss: 0.5646 +/- 0.0068
INFO:root:Epoch no. 196 of 500 (samples: 141442)
INFO:root:Loss: 0.5609 +/- 0.0063
INFO:root:Epoch no. 197 of 500 (samples: 141442)
INFO:root:Loss: 0.559 +/- 0.005
INFO:root:Epoch no. 198 of 500 (samples: 141442)
INFO:root:Loss: 0.5627 +/- 0.0061
INFO:root:Epoch no. 199 of 500 (samples: 141442)
INFO:root:Loss: 0.5607 +/- 0.0059
INFO:root:Epoch no. 200 of 500 (samples: 141442)
INFO:root:Loss: 0.5585 +/- 0.0076
INFO:root:Epoch no. 201 of 500 (samples: 141442)
INFO:root:Loss: 0.5574 +/- 0.0063
INFO:root:Epoch no. 202 of 500 (samples: 141442)
INFO:root:Loss: 0.5535 +/- 0.0068
INFO:root:Epoch no. 203 of 500 (samples: 141442)
INFO:root:Loss: 0.5542 +/- 0.0079
INFO:root:Epoch no. 204 of 500 (samples: 141442)
INFO:root:Loss: 0.5524 +/- 0.0041
INFO:root:Epoch no. 205 of 500 (samples: 141442)
INFO:root:Loss: 0.5485 +/- 0.0076
INFO:root:Epoch no. 206 of 500 (samples: 141442)
INFO:root:Loss: 0.5526 +/- 0.0054
INFO:root:Epoch no. 207 of 500 (samples: 141442)
INFO:root:Loss: 0.5552 +/- 0.0094
INFO:root:Epoch no. 208 of 500 (samples: 141442)
INFO:root:Loss: 0.5511 +/- 0.0068
INFO:root:Epoch no. 209 of 500 (samples: 141442)
INFO:root:Loss: 0.5489 +/- 0.0097
INFO:root:Epoch no. 210 of 500 (samples: 141442)
INFO:root:Loss: 0.545 +/- 0.0039
INFO:root:Epoch no. 211 of 500 (samples: 141442)
INFO:root:Loss: 0.5476 +/- 0.0063
INFO:root:Epoch no. 212 of 500 (samples: 141442)
INFO:root:Loss: 0.5447 +/- 0.0058
INFO:root:Epoch no. 213 of 500 (samples: 141442)
INFO:root:Loss: 0.5455 +/- 0.0086
INFO:root:Epoch no. 214 of 500 (samples: 141442)
INFO:root:Loss: 0.5444 +/- 0.0089
INFO:root:Epoch no. 215 of 500 (samples: 141442)
INFO:root:Loss: 0.5391 +/- 0.0075
INFO:root:Epoch no. 216 of 500 (samples: 141442)
INFO:root:Loss: 0.5439 +/- 0.0091
INFO:root:Epoch no. 217 of 500 (samples: 141442)
INFO:root:Loss: 0.5426 +/- 0.0042
INFO:root:Epoch no. 218 of 500 (samples: 141442)
INFO:root:Loss: 0.5387 +/- 0.0049
INFO:root:Epoch no. 219 of 500 (samples: 141442)
INFO:root:Loss: 0.5385 +/- 0.0054
INFO:root:Epoch no. 220 of 500 (samples: 141442)
INFO:root:Loss: 0.5382 +/- 0.0081
INFO:root:Epoch no. 221 of 500 (samples: 141442)
INFO:root:Loss: 0.5332 +/- 0.0075
INFO:root:Epoch no. 222 of 500 (samples: 141442)
INFO:root:Loss: 0.5348 +/- 0.0075
INFO:root:Epoch no. 223 of 500 (samples: 141442)
INFO:root:Loss: 0.5349 +/- 0.01
INFO:root:Epoch no. 224 of 500 (samples: 141442)
INFO:root:Loss: 0.5324 +/- 0.0062
INFO:root:Epoch no. 225 of 500 (samples: 141442)
INFO:root:Loss: 0.5333 +/- 0.0057
INFO:root:Epoch no. 226 of 500 (samples: 141442)
INFO:root:Loss: 0.5316 +/- 0.0088
INFO:root:Epoch no. 227 of 500 (samples: 141442)
INFO:root:Loss: 0.5275 +/- 0.0066
INFO:root:Epoch no. 228 of 500 (samples: 141442)
INFO:root:Loss: 0.5317 +/- 0.0074
INFO:root:Epoch no. 229 of 500 (samples: 141442)
INFO:root:Loss: 0.5288 +/- 0.0058
INFO:root:Epoch no. 230 of 500 (samples: 141442)
INFO:root:Loss: 0.5261 +/- 0.0068
INFO:root:Epoch no. 231 of 500 (samples: 141442)
INFO:root:Loss: 0.5293 +/- 0.0047
INFO:root:Epoch no. 232 of 500 (samples: 141442)
INFO:root:Loss: 0.5269 +/- 0.0062
INFO:root:Epoch no. 233 of 500 (samples: 141442)
INFO:root:Loss: 0.5248 +/- 0.0087
INFO:root:Epoch no. 234 of 500 (samples: 141442)
INFO:root:Loss: 0.5241 +/- 0.0072
INFO:root:Epoch no. 235 of 500 (samples: 141442)
INFO:root:Loss: 0.5266 +/- 0.0096
INFO:root:Epoch no. 236 of 500 (samples: 141442)
INFO:root:Loss: 0.5203 +/- 0.0108
INFO:root:Epoch no. 237 of 500 (samples: 141442)
INFO:root:Loss: 0.5218 +/- 0.0103
INFO:root:Epoch no. 238 of 500 (samples: 141442)
INFO:root:Loss: 0.5208 +/- 0.0058
INFO:root:Epoch no. 239 of 500 (samples: 141442)
INFO:root:Loss: 0.5201 +/- 0.0078
INFO:root:Epoch no. 240 of 500 (samples: 141442)
INFO:root:Loss: 0.5192 +/- 0.0038
INFO:root:Epoch no. 241 of 500 (samples: 141442)
INFO:root:Loss: 0.5207 +/- 0.0058
INFO:root:Epoch no. 242 of 500 (samples: 141442)
INFO:root:Loss: 0.5202 +/- 0.0067
INFO:root:Epoch no. 243 of 500 (samples: 141442)
INFO:root:Loss: 0.5163 +/- 0.0066
INFO:root:Epoch no. 244 of 500 (samples: 141442)
INFO:root:Loss: 0.5129 +/- 0.0062
INFO:root:Epoch no. 245 of 500 (samples: 141442)
INFO:root:Loss: 0.515 +/- 0.0073
INFO:root:Epoch no. 246 of 500 (samples: 141442)
INFO:root:Loss: 0.5128 +/- 0.0034
INFO:root:Epoch no. 247 of 500 (samples: 141442)
INFO:root:Loss: 0.5099 +/- 0.007
INFO:root:Epoch no. 248 of 500 (samples: 141442)
INFO:root:Loss: 0.5114 +/- 0.0068
INFO:root:Epoch no. 249 of 500 (samples: 141442)
INFO:root:Loss: 0.5131 +/- 0.0052
INFO:root:Epoch no. 250 of 500 (samples: 141442)
INFO:root:Loss: 0.5111 +/- 0.0052
INFO:root:Epoch no. 251 of 500 (samples: 141442)
INFO:root:Loss: 0.5088 +/- 0.0078
INFO:root:Epoch no. 252 of 500 (samples: 141442)
INFO:root:Loss: 0.5045 +/- 0.0084
INFO:root:Epoch no. 253 of 500 (samples: 141442)
INFO:root:Loss: 0.507 +/- 0.0081
INFO:root:Epoch no. 254 of 500 (samples: 141442)
INFO:root:Loss: 0.5057 +/- 0.008
INFO:root:Epoch no. 255 of 500 (samples: 141442)
INFO:root:Loss: 0.5045 +/- 0.0057
INFO:root:Epoch no. 256 of 500 (samples: 141442)
INFO:root:Loss: 0.503 +/- 0.0064
INFO:root:Epoch no. 257 of 500 (samples: 141442)
INFO:root:Loss: 0.5061 +/- 0.0046
INFO:root:Epoch no. 258 of 500 (samples: 141442)
INFO:root:Loss: 0.5036 +/- 0.0074
INFO:root:Epoch no. 259 of 500 (samples: 141442)
INFO:root:Loss: 0.4986 +/- 0.007
INFO:root:Epoch no. 260 of 500 (samples: 141442)
INFO:root:Loss: 0.5015 +/- 0.0064
INFO:root:Epoch no. 261 of 500 (samples: 141442)
INFO:root:Loss: 0.4972 +/- 0.0086
INFO:root:Epoch no. 262 of 500 (samples: 141442)
INFO:root:Loss: 0.4997 +/- 0.0056
INFO:root:Epoch no. 263 of 500 (samples: 141442)
INFO:root:Loss: 0.5013 +/- 0.0059
INFO:root:Epoch no. 264 of 500 (samples: 141442)
INFO:root:Loss: 0.4988 +/- 0.0079
INFO:root:Epoch no. 265 of 500 (samples: 141442)
INFO:root:Loss: 0.4972 +/- 0.0064
INFO:root:Epoch no. 266 of 500 (samples: 141442)
Traceback (most recent call last):
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/hyper-cli.py", line 324, in <module>
    main(sys.argv[1:])
  File "./bin/hyper-cli.py", line 293, in main
    visualize=is_visualize)
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/learning/core.py", line 185, in pairwise_training
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/models.py", line 409, in fit
    sample_weight=sample_weight)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/training.py", line 1052, in fit
    callback_metrics=callback_metrics)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/training.py", line 790, in _fit_loop
    outs = f(ins_batch)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/backend/theano_backend.py", line 518, in __call__
    return self.function(*inputs)
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/usr/local/lib/python3.4/dist-packages/theano/gof/link.py", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/usr/local/lib/python3.4/dist-packages/six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.4/dist-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
MemoryError: 
Apply node that caused the error: Elemwise{mul,no_inplace}(Reshape{3}.0, Reshape{3}.0)
Toposort index: 77
Inputs types: [TensorType(float32, (False, False, True)), TensorType(float32, 3D)]
Inputs shapes: [(42411, 50, 1), (42411, 50, 50)]
Inputs strides: [(400, 4, 4), (10200, 200, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Sum{axis=[1], acc_dtype=float64}(Elemwise{mul,no_inplace}.0)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File "./bin/hyper-cli.py", line 293, in main
    visualize=is_visualize)
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/learning/core.py", line 78, in pairwise_training
    merge_layer = Merge([predicate_encoder, entity_encoder], mode=merge_function, output_shape=lambda _: (None, 1))
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 1116, in __init__
    self.add_inbound_node(layers, node_indices, tensor_indices)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 543, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 153, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors, mask=input_masks))
  File "/home/insight/.local/lib/python3.4/site-packages/Keras-1.0.3-py3.4.egg/keras/engine/topology.py", line 1193, in call
    return self.mode(inputs, **arguments)
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/layers/core.py", line 28, in latent_distance_binary_merge_function
    return merge_function(args, similarity=similarity_function)
  File "/home/insight/.local/lib/python3.4/site-packages/hyper-0.0.1-py3.4.egg/hyper/layers/binary/merge_functions.py", line 243, in affine_merge_function
    affine_transformation = (rx * rW).sum(1) + pred_b

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
